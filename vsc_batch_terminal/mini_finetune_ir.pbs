#!/bin/bash

#PBS -A lcalculus
#PBS -l nodes=1:ppn=9:gpus=1:skylake
#PBS -l partition=gpu
#PBS -l walltime=00:10:00
#PBS -l pmem=5gb
#PBS -m abe
#PBS -j oe
#PBS -M nathan.cornille@kuleuven.be
#PBS -N mini_finetune_ir
#PBS -l qos=debugging

source $HOME/.bashrc
conda activate devlbert

CKPT_ROOT_DIR=/scratch/leuven/336/vsc33642
FINETUNED_DIR=debug_ckpts_downstream
PRETRAINED_CKPT_NAME=v6_devlbert_checkpunten/epoch=3-step=22687-0.3.ckpt
FINETUNED_CKPT_NAME=devlbert_ir
FINETUNED_CKPT_EPOCH=1

# Finetuning on IR
python train_tasks.py --bert_model bert-base-uncased --from_pretrained $CKPT_ROOT_DIR/$PRETRAINED_CKPT_NAME --config_file config/bert_base_6layer_6conect.json --learning_rate 4e-5 --tasks 3 --save_name $FINETUNED_CKPT_NAME --use_ema --ema_decay_ratio 0.9999 --num_workers 0 --batch_size 8 --mini --output_dir $CKPT_ROOT_DIR/$FINETUNED_DIR

# Evaluating on IR
python eval_retrieval.py --bert_model bert-base-uncased --from_pretrained $CKPT_ROOT_DIR/$FINETUNED_DIR/RetrievalFlickr30k_bert_base_6layer_6conect-$FINETUNED_CKPT_NAME/pytorch_model_${FINETUNED_CKPT_EPOCH}_ema.bin --config_file config/bert_base_6layer_6conect.json --tasks 3 --split test --batch_size 1 --mini

